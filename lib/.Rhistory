packages.used <- c("R.matlab","readxl", "dplyr", "ggplot2", "caret","pROC","randomForest", "magrittr", "e1071","grid","gridExtra", "ROSE", "DMwR")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0){
install.packages(packages.needed, dependencies = TRUE)
}
library(R.matlab)
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(randomForest)
library(magrittr)
library(e1071)
library(grid)
library(gridExtra)
library(ROSE)
library(DMwR)
set.seed(2040)
train_dir <- "../data/train_set/" #may need to be changed to local directory
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
K <- 5  # number of CV folds
run.fudicial.list <- FALSE
run.feature.train <- FALSE # process features for training set
run.feature.test <- FALSE # process features for test set
run.cv.rf <- FALSE # run cross-validation on the training set for random forest
run.train.rf <- FALSE # run evaluation on entire train set
run.test.rf <- TRUE # run evaluation on an independent test set
run.rose <- TRUE # regenerate balanced data with ROSE method
run.cv.rf.rose <- FALSE #run cross-validation on the training set for randome forecast with ROSE
run.test.rf.rose <- TRUE # run evaluation on an independent test set
hyper_grid_rf <- expand.grid(
ntree = c(200, 500, 800, 1000),
mtry = c(20,50))
info <- read.csv(train_label_path)
n_files <- length(list.files(train_image_dir))
if (run.fudicial.list){
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
# otherwise load the data stored for convenience
} else {
load(file="../output/fiducial_pt_list.RData")
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
save(dat_train, tm_feature_train, file="../output/feature_train.RData")
}else{
load(file="../output/feature_train.RData")
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
save(dat_test, tm_feature_test, file="../output/feature_test.RData")
}else{
load(file="../output/feature_test.RData")
}
source("../lib/train_rf.R")
source("../lib/test_rf.R")
source("../lib/cross_validation_rf.R")
source("../lib/ROSE.R")
# Training data with ROSE is too big to upload to Github, so we need to train the data again.
if(run.rose){
dat_train_rose <- use_rose(dat_train)
save(dat_train_rose, file="../output/dat_train_rose.RData")
}else{
load("../output/dat_train_rose.RData")
}
K <- 5  # number of CV folds
run.fudicial.list <- FALSE
run.feature.train <- TRUE # process features for training set
run.feature.test <- TRUE # process features for test set
run.cv.rf <- FALSE # run cross-validation on the training set for random forest
run.train.rf <- FALSE # run evaluation on entire train set
run.test.rf <- TRUE # run evaluation on an independent test set
run.rose <- TRUE # regenerate balanced data with ROSE method
run.cv.rf.rose <- TRUE #run cross-validation on the training set for randome forecast with ROSE
run.test.rf.rose <- TRUE # run evaluation on an independent test set
cat("Number of records with label 0 after ROSE (basic emotion): ", length(which(dat_train_rose$label == 0)), "\n")
cat("Number of records with label 1 after ROSE (complex emotion): ", length(which(dat_train_rose$label == 1)), "\n")
1210+1190
# split features and labels
feature_train_rose = as.matrix(dat_train_rose[, -6007])
label_train_rose = dat_train_rose$label
# run cross-validation
if(run.cv.rf.rose){
res_cv_rf_rose <- matrix(0, nrow = nrow(hyper_grid_rf), ncol = 4)
for (i in 1:nrow(hyper_grid_rf)){
print(hyper_grid_rf$ntree[i])
print(hyper_grid_rf$mtry[i])
res_cv_rf_rose[i,] <- cv.function_rf(features = feature_train_rose,
labels = label_train_rose,
K,
ntree = hyper_grid_rf$ntree[i],
mtry = hyper_grid_rf$mtry[i])
}
save(res_cv_rf_rose, file="../output/res_cv_rf_rose.RData")
}else{
load("../output/res_cv_rf_rose.RData")
}
packages.used <- c("R.matlab","readxl", "dplyr", "ggplot2", "caret","pROC","randomForest", "magrittr", "e1071","grid","gridExtra", "ROSE", "DMwR")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0){
install.packages(packages.needed, dependencies = TRUE)
}
library(R.matlab)
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(randomForest)
library(magrittr)
library(e1071)
library(grid)
library(gridExtra)
library(ROSE)
library(DMwR)
set.seed(2040)
train_dir <- "../data/train_set/" #may need to be changed to local directory
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
K <- 5  # number of CV folds
run.fudicial.list <- FALSE
run.feature.train <- FALSE # process features for training set
run.feature.test <- FALSE # process features for test set
run.rose <- TRUE # regenerate balanced data with ROSE method
run.cv.rf <- FALSE # run cross-validation on the training set for random forest
run.train.rf <- FALSE # run evaluation on entire train set
run.test.rf <- TRUE # run evaluation on an independent test set
hyper_grid_rf <- expand.grid(
ntree = c(200, 500, 800, 1000),
mtry = c(20,50))
n_files <- length(list.files(train_image_dir))
if (run.fudicial.list){
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
# otherwise load the data stored for convenience
} else {
load(file="../output/fiducial_pt_list.RData")
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
save(dat_train, tm_feature_train, file="../output/feature_train.RData")
}else{
load(file="../output/feature_train.RData")
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
save(dat_test, tm_feature_test, file="../output/feature_test.RData")
}else{
load(file="../output/feature_test.RData")
}
source("../lib/ROSE.R")
# Training data with ROSE is too big to upload to Github, so we need to train the data again.
if(run.rose){
dat_train_rose <- use_rose(dat_train)
save(dat_train_rose, file="../output/dat_train_rose.RData")
}else{
load("../output/dat_train_rose.RData")
}
cat("Number of records with label 0 after ROSE (basic emotion): ", length(which(dat_train_rose$label == 0)), "\n")
cat("Number of records with label 1 after ROSE (complex emotion): ", length(which(dat_train_rose$label == 1)), "\n")
# create PCA features from Yiwen's function
source("../lib/feature_pca.R")
load("../output/dat_train_rose.RData")
# train a PCA model
tm_pca_feature <- system.time({model_pca <- feature_pca(dat_train_rose)})
# train both the training and test sets
if(TRUE){
feature_pca_train <- predict(model_pca, dat_train_rose[, -6007])
feature_pca_test <- predict(model_pca, dat_test[, -6007])
save(feature_pca_train, file="../output/feature_pca_train.RData")
save(feature_pca_test, file="../output/feature_pca_test.RData")
}else{
load(feature_pca_train, file="../output/feature_pca_train.RData")
load(feature_pca_test, file="../output/feature_pca_test.RData")
}
source("../lib/train_rf.R")
source("../lib/test_rf.R")
source("../lib/cross_validation_rf.R")
table(feature_pca_train)
K <- 5  # number of CV folds
run.fudicial.list <- FALSE
run.feature.train <- FALSE # process features for training set
run.feature.test <- FALSE # process features for test set
run.rose <- TRUE # regenerate balanced data with ROSE method
run.cv.rf <- TRUE # run cross-validation on the training set for random forest
run.train.rf <- TRUE # run evaluation on entire train set
run.test.rf <- TRUE # run evaluation on an independent test set
K <- 5  # number of CV folds
run.fudicial.list <- FALSE
run.feature.train <- FALSE # process features for training set
run.feature.test <- FALSE # process features for test set
run.rose <- TRUE # regenerate balanced data with ROSE method
run.cv.rf <- TRUE # run cross-validation on the training set for random forest
run.train.rf <- TRUE # run evaluation on entire train set
run.test.rf <- TRUE # run evaluation on an independent test set
# split features and labels
feature_train = as.matrix(feature_pca_train)
label_train = dat_train$label
# run cross-validation
if(run.cv.rf){
res_cv_rf_pca <- matrix(0, nrow = nrow(hyper_grid_rf), ncol = 4)
for (i in 1:nrow(hyper_grid_rf)){
print(hyper_grid_rf$ntree[i])
print(hyper_grid_rf$mtry[i])
res_cv_rf_pca[i,] <- cv.function_rf(features = feature_train,
labels = label_train,
K,
ntree = hyper_grid_rf$ntree[i],
mtry = hyper_grid_rf$mtry[i])
}
save(res_cv_rf_pca, file="../output/res_cv_rf_pca.RData")
}else{
load("../output/res_cv_rf_pca.RData")
}
tm_train_rf_pca <- system.time(fit_train_rf_pca <- train_rf(feature_train, label_train, ntree = 800, mtry = 50))
tm_test_rf_pca = NA
feature_test <- as.matrix(feature_pca_test)
label_test <- dat_test$label
tm_test_rf_pca <- system.time(label_pred <- as.integer(predict(fit_train_rf_pca, feature_test))
ï¼‰
tm_test_rf_pca <- system.time(label_pred <- as.integer(predict(fit_train_rf_pca, feature_test)))
accu_rf = mean(label_pred == as.integer(label_test))
auc_rf <- roc(label_pred, as.integer(label_test))$auc
cat("The unweighted accuracy of the random forest model is ", accu_rf*100, "%.\n")
cat("The unweighted AUC of the random forest model is ", auc_rf, ".\n")
packages.used <- c("R.matlab","readxl", "dplyr", "ggplot2", "caret","pROC","randomForest", "magrittr", "e1071","grid","gridExtra", "ROSE", "DMwR")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0){
install.packages(packages.needed, dependencies = TRUE)
}
library(R.matlab)
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(randomForest)
library(magrittr)
library(e1071)
library(grid)
library(gridExtra)
library(ROSE)
library(DMwR)
set.seed(2020)
train_dir <- "../data/train_set/" #may need to be changed to local directory
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
K <- 5  # number of CV folds
run.fudicial.list <- TRUE
run.feature.train <- TRUE # process features for training set
run.feature.test <- TRUE # process features for test set
run.rose <- TRUE # regenerate balanced data with ROSE method
run.cv.rf <- TRUE # run cross-validation on the training set for random forest
run.train.rf <- TRUE # run evaluation on entire train set
run.test.rf <- TRUE # run evaluation on an independent test set
hyper_grid_rf <- expand.grid(
ntree = c(200, 500, 800, 1000),
mtry = c(20,50))
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index, train_idx)
n_files <- length(list.files(train_image_dir))
if (run.fudicial.list){
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
# otherwise load the data stored for convenience
} else {
load(file="../output/fiducial_pt_list.RData")
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
save(dat_train, tm_feature_train, file="../output/feature_train.RData")
}else{
load(file="../output/feature_train.RData")
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
save(dat_test, tm_feature_test, file="../output/feature_test.RData")
}else{
load(file="../output/feature_test.RData")
}
source("../lib/ROSE.R")
# Training data with ROSE is too big to upload to Github, so we need to train the data again.
if(run.rose){
dat_train_rose <- use_rose(dat_train)
save(dat_train_rose, file="../output/dat_train_rose.RData")
}else{
load("../output/dat_train_rose.RData")
}
cat("Number of records with label 0 after ROSE (basic emotion): ", length(which(dat_train_rose$label == 0)), "\n")
cat("Number of records with label 1 after ROSE (complex emotion): ", length(which(dat_train_rose$label == 1)), "\n")
# create PCA features from Yiwen's function
source("../lib/feature_pca.R")
load("../output/dat_train_rose.RData")
# train a PCA model
tm_pca_feature <- system.time({model_pca <- feature_pca(dat_train_rose)})
# train both the training and test sets
if(TRUE){
feature_pca_train <- predict(model_pca, dat_train_rose[, -6007])
feature_pca_test <- predict(model_pca, dat_test[, -6007])
save(feature_pca_train, file="../output/feature_pca_train.RData")
save(feature_pca_test, file="../output/feature_pca_test.RData")
}else{
load(feature_pca_train, file="../output/feature_pca_train.RData")
load(feature_pca_test, file="../output/feature_pca_test.RData")
}
source("../lib/train_rf.R")
source("../lib/test_rf.R")
source("../lib/cross_validation_rf.R")
if (run.train.rf) {
tm_train_rf_pca <- system.time(fit_train_rf_pca <- train_rf(feature_train, label_train, ntree = 800, mtry = 50))
save(fit_train_rf_pca, tm_train_rf_pca, file="../output/fit_train_rf_pca.RData")
} else {
load(file="../output/fit_train_rf_pca.RData")
}
feature_train = as.matrix(feature_pca_train)
label_train = dat_train$label
if (run.train.rf) {
tm_train_rf_pca <- system.time(fit_train_rf_pca <- train_rf(feature_train, label_train, ntree = 800, mtry = 50))
save(fit_train_rf_pca, tm_train_rf_pca, file="../output/fit_train_rf_pca.RData")
} else {
load(file="../output/fit_train_rf_pca.RData")
}
tm_test_rf_pca = NA
feature_test <- as.matrix(feature_pca_test)
label_test <- dat_test$label
if(run.test.rf){
load(file="../output/fit_train_rf_pca.RData")
tm_test_rf_pca <- system.time(label_pred <- as.integer(predict(fit_train_rf_pca, feature_test)))
}
label_pred
label_test
label_pred
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
label_pred <- ifelse(label_test == 2, 1, 0)
accu <- sum(weight_test * (label_pred == label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred, label_test, weight_test)
install.packages('WeightedROC')
library(WeightedROC)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
label_pred <- ifelse(label_test == 2, 1, 0)
accu <- sum(weight_test * (label_pred == label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred, label_test, weight_test)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
label_pred <- ifelse(label_test == 2, 1, 0)
accu <- sum(weight_test * (label_pred == label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(label_pred, label_test, weight_test)
auc <- WeightedAUC(tpr.fpr)
cat("The unweighted accuracy of the random forest model is ", accu*100, "%.\n")
cat("The unweighted AUC of the random forest model is ", auc, ".\n")
cat("The weighted accuracy of the random forest model is ", accu*100, "%.\n")
cat("The weighted AUC of the random forest model is ", auc, ".\n")
